# ðŸ“ˆ Proyecto: AnÃ¡lisis Financiero con Streaming y Power BI (Business Analytics)

Este repositorio contiene un sistema de anÃ¡lisis de datos bursÃ¡tiles con procesamiento de datos en tiempo real y visualizaciÃ³n avanzada en **Power BI**. EstÃ¡ orientado al curso de Business Analytics, con foco en generar insights Ãºtiles para la toma de decisiones empresariales.

---

## ðŸ› ï¸ TecnologÃ­as utilizadas

- **Apache Kafka**: streaming de datos financieros  
- **Apache Spark**: procesamiento ETL en tiempo real  
- **Python**: transformaciÃ³n, modelado y predicciÃ³n  
- **Power BI**: visualizaciÃ³n de KPIs, mÃ©tricas e insights  
- **Docker**: orquestaciÃ³n de contenedores (Kafka)

## ðŸ“ Estructura general del proyecto

```
â”œâ”€â”€ config/ # Rutas y configuraciÃ³n
â”œâ”€â”€ kafka_services/ # Docker Compose 
â”œâ”€â”€ machine_learning/ # Entrenamiento y predicciÃ³n de modelos ML
â”œâ”€â”€ output/ # Datos procesados (Parquet/CSV/ZIP)                
â”œâ”€â”€ power_bi/ # Reporte Power BI (.pbix)             
â”œâ”€â”€ producer/ # Scripts para enviar datos a Kafka
â”œâ”€â”€ raw_data/  # Datos crudos (CSV y PDF)             
â”œâ”€â”€ spark/ # Procesamiento en streaming con Spark
â”œâ”€â”€ static_etl/ # Procesamiento para datos estÃ¡ticos
â”œâ”€â”€ utils/ # Utilidades (conversiÃ³n, helpers)
â”œâ”€â”€ venv/ âš ï¸ No incluido: entorno virtual local 
â”œâ”€â”€ .env âš ï¸ No incluido: debes crearlo localmente con tus variables sensibles
â”œâ”€â”€ .gitignore # Archivos/carpetas ignorados por Git 
â”œâ”€â”€ check_env.py # Verificador de variables de entorno
â”œâ”€â”€ Readme.markdown # DocumentaciÃ³n general                
â””â”€â”€ requirements.txt # Dependencias del proyecto
```

## ðŸ§° Requisitos del sistema

Instala los siguientes componentes antes de ejecutar el proyecto:

- Python 3.8+  
- Java JDK 8 âœ… obligatorio para Spark  
- Apache Hadoop (cliente local)  
- Apache Spark (local)  
- Docker Desktop (para correr Kafka/Zookeeper)  
- Power BI Desktop (para abrir los reportes)

## ðŸš€ Pasos para ejecutar el proyecto

### 1. Clonar y preparar entorno

```bash
git clone https://github.com/4wful/real-time-data-analytics.git
cd real-time-data-analytics
python -m venv venv
source .\venv\Scripts\Activate.ps1 
pip install -r requirements.txt
```

### 2. Configurar variables sensibles

Crea un archivo `.env` en la raÃ­z del proyecto con el siguiente contenido:

```env
API_KEY=tu_api_key_aqui  # (ALPHA VANTAGE API)
KAFKA_TOPIC=nombre_de_tu_topic
KAFKA_BOOTSTRAP_SERVERS=tus_local_host
```

### 3. Levantar servicios Kafka

```bash
cd kafka_services
docker-compose up --build
```

Crear y verificar el tÃ³pico:

```bash
# Crear tÃ³pico
docker exec -it kafka-broker-1 kafka-topics --create \
  --bootstrap-server kafka-broker-1:29092 \
  --replication-factor 3 --partitions 3 \
  --topic mercados-bursatiles --if-not-exists

# Verificar tÃ³picos
docker exec -it kafka-broker-1 kafka-topics --list \
  --bootstrap-server kafka-broker-1:29092
```

### 4. Ejecutar el flujo de datos

```bash
# a. Enviar datos a Kafka
python producer/api_to_kafka.py

# b. Procesar datos en Spark Streaming
.\run_spark_api.ps1

# c. ConversiÃ³n Parquet a CSV
.\run_parquet_csv.ps1

# d. ETL estÃ¡tico desde PDF
.\run_static_etl.ps1
```

### 5. Modelo de predicciÃ³n (opcional)

```bash
python machine_learning/model_train.py
python machine_learning/inference.py
```

## ðŸ“Š VisualizaciÃ³n final en Power BI

DirÃ­gete a la carpeta `output/dashboard_data/` y conecta Power BI al archivo CSV para construir tu dashboard personalizado.

ðŸ“Œ *PrÃ³ximamente se aÃ±adirÃ¡ una imagen de referencia del dashboard final.*

**Ejemplo de KPIs sugeridos:**

- PredicciÃ³n de precios de acciones  
- Volumen negociado  
- Comparativas por trimestre o regiÃ³n

---

## ðŸ‘¨â€ðŸ« Autor

**Grupo 4** â€“ Trabajo final para el curso **Business Analytics** (AÃ±o 2025), dictado por el docente **Lira Camacho**.

Â¡Explora, ejecuta y aprende del flujo completo de datos en tiempo real! ðŸ“ˆ

> **Todos los derechos reservados al Grupo 4.**
